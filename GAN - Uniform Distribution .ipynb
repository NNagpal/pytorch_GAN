{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This GAN is trained to generate data with uniform distribution. The Real data (R) used in training is sample set from uniform distribution U(1,5). The Noise data (I) is samplesd from a normal distribution N(10,1.25)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libs and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, f):\n",
    "        super(Generator, self).__init__()\n",
    "        self.map1 = nn.Linear(input_size, hidden_size)\n",
    "        self.map2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.map3 = nn.Linear(hidden_size, output_size)\n",
    "        self.f = f\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.map1(x)\n",
    "        x = self.f(x)\n",
    "        x = self.map2(x)\n",
    "        x = self.f(x)\n",
    "        x = self.map3(x)\n",
    "        return x\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, f):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.map1 = nn.Linear(input_size, hidden_size)\n",
    "        self.map2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.map3 = nn.Linear(hidden_size, output_size)\n",
    "        self.f = f\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.f(self.map1(x))\n",
    "        x = self.f(self.map2(x))\n",
    "        return self.f(self.map3(x))\n",
    "\n",
    "def extract(v):\n",
    "    return v.data.storage().tolist()\n",
    "\n",
    "def stats(d):\n",
    "    return [np.mean(d), np.std(d)]\n",
    "\n",
    "def get_moments(d):\n",
    "    mean = torch.mean(d)\n",
    "    diffs = d - mean\n",
    "    var = torch.mean(torch.pow(diffs, 2.0))\n",
    "    std = torch.pow(var, 0.5)\n",
    "    final = torch.cat((mean.reshape(1,), std.reshape(1,)))\n",
    "    return final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian and Unifrom Sampler Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uniform Distribution Parameter\n",
    "data_lower = 1\n",
    "data_upper = 5\n",
    "\n",
    "#Gaussian Distribution Parameters\n",
    "data_mean = 10\n",
    "data_stddev = 1.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real (R) and Noise (I) Data Samplers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real Data Sampler - R\n",
    "# Uniform Distribution with Parameters (a,b) = ()\n",
    "\n",
    "def get_distribution_sampler(a,b):\n",
    "    return lambda m, n: (a-b) * torch.rand(m, n) + b\n",
    "\n",
    "# Noise/Fake Data Sampler - I\n",
    "# Gaussian Distribution\n",
    "def get_generator_input_sampler(mu, sigma):\n",
    "    return lambda n: torch.Tensor(np.random.normal(mu, sigma, (n,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative (G) and Discrimative (D) Models Hyper Paratemer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_input_size = 1      # Random noise dimension coming into generator, per output vector\n",
    "g_hidden_size = 5     # Generator complexity\n",
    "g_output_size = 1     # Size of generated output vector\n",
    "d_input_size = 500    # Minibatch size - cardinality of distributions\n",
    "d_hidden_size = 10    # Discriminator complexity\n",
    "d_output_size = 1     # Single dimension for 'real' vs. 'fake' classification\n",
    "minibatch_size = d_input_size\n",
    "\n",
    "d_learning_rate = 1e-3\n",
    "g_learning_rate = 1e-3\n",
    "sgd_momentum = 0.9\n",
    "\n",
    "num_epochs = 5000\n",
    "print_interval = 100\n",
    "d_steps = 20\n",
    "g_steps = 20\n",
    "\n",
    "dfe, dre, ge = 0, 0, 0\n",
    "d_real_data, d_fake_data, g_fake_data = None, None, None\n",
    "\n",
    "(name, preprocess, d_input_func) = (\"2 Moments\", lambda data: get_moments(data), lambda x: 2)\n",
    "\n",
    "discriminator_activation_function = torch.sigmoid\n",
    "generator_activation_function = torch.tanh\n",
    "\n",
    "d_sampler = get_distribution_sampler(data_lower,data_upper)\n",
    "gi_sampler = get_generator_input_sampler(data_mean,data_stddev)\n",
    "\n",
    "G = Generator(input_size=g_input_size,\n",
    "                  hidden_size=g_hidden_size,\n",
    "                  output_size=g_output_size,\n",
    "                  f=generator_activation_function)\n",
    "D = Discriminator(input_size=d_input_func(d_input_size),\n",
    "                  hidden_size=d_hidden_size,\n",
    "                  output_size=d_output_size,\n",
    "                  f=discriminator_activation_function)\n",
    "criterion = nn.BCELoss()  # Binary cross entropy: http://pytorch.org/docs/nn.html#bceloss\n",
    "d_optimizer = optim.SGD(D.parameters(), lr=d_learning_rate, momentum=sgd_momentum)\n",
    "g_optimizer = optim.SGD(G.parameters(), lr=g_learning_rate, momentum=sgd_momentum)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training G and D Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: D (0.5011354684829712 real_err, 0.9274313449859619 fake_err) G (0.5066295862197876 err); Real Dist ([3.006579041481018, 1.1488099434083934]),  Fake Dist ([-0.19709156453609467, 3.3467388593572392e-06]) \n",
      "Epoch 100: D (0.6901128888130188 real_err, 0.6882188320159912 fake_err) G (0.6964195966720581 err); Real Dist ([3.003831624984741, 1.1492294472304558]),  Fake Dist ([4.26985502243042, 0.0001671132534811183]) \n",
      "Epoch 200: D (0.18668901920318604 real_err, 0.1884099543094635 fake_err) G (1.7607507705688477 err); Real Dist ([2.9981406927108765, 1.147893298305485]),  Fake Dist ([1.441666841506958, 0.00015362305674211532]) \n",
      "Epoch 300: D (0.028866177424788475 real_err, 0.03541802242398262 fake_err) G (3.3588197231292725 err); Real Dist ([2.9912586212158203, 1.1495651879431745]),  Fake Dist ([1.8503392934799194, 7.977111234951239e-05]) \n",
      "Epoch 400: D (0.016295218840241432 real_err, 0.016464080661535263 fake_err) G (4.115121364593506 err); Real Dist ([3.0013235807418823, 1.1529543245637115]),  Fake Dist ([1.8117483258247375, 0.00010898840069495503]) \n",
      "Epoch 500: D (0.008472349494695663 real_err, 0.010271972045302391 fake_err) G (4.583728313446045 err); Real Dist ([3.0011374950408936, 1.1534637171456776]),  Fake Dist ([1.7871191501617432, 0.0001703481475971037]) \n",
      "Epoch 600: D (0.006254762411117554 real_err, 0.007337722461670637 fake_err) G (4.918549060821533 err); Real Dist ([2.9997082948684692, 1.1538203126013142]),  Fake Dist ([1.7841852307319641, 5.5853544151535214e-05]) \n",
      "Epoch 700: D (0.0049689277075231075 real_err, 0.005635494831949472 fake_err) G (5.18161153793335 err); Real Dist ([3.0042203664779663, 1.1516292568717763]),  Fake Dist ([1.7702491283416748, 0.0001610564304554435]) \n",
      "Epoch 800: D (0.004373862873762846 real_err, 0.004554913844913244 fake_err) G (5.393813610076904 err); Real Dist ([2.9986883401870728, 1.153500677531641]),  Fake Dist ([1.7666734457015991, 9.09900004538873e-05]) \n",
      "Epoch 900: D (0.0038939134683459997 real_err, 0.0038044608663767576 fake_err) G (5.573672771453857 err); Real Dist ([2.999863624572754, 1.1538052393712843]),  Fake Dist ([1.7640191316604614, 0.0003228699637890963]) \n",
      "Epoch 1000: D (0.0029847417026758194 real_err, 0.0032818466424942017 fake_err) G (5.718108654022217 err); Real Dist ([3.0029280185699463, 1.1504234672969262]),  Fake Dist ([1.7508200407028198, 0.004870580470589512]) \n",
      "Epoch 1100: D (0.6894819140434265 real_err, 0.6850719451904297 fake_err) G (0.7012583017349243 err); Real Dist ([3.0026403665542603, 1.1468745131415528]),  Fake Dist ([1.7753292322158813, 2.7622572957230496]) \n",
      "Epoch 1200: D (0.6949049234390259 real_err, 0.6945935487747192 fake_err) G (0.6894740462303162 err); Real Dist ([3.00811505317688, 1.1471929781431414]),  Fake Dist ([1.4027848839759827, 1.6272703645961664]) \n",
      "Epoch 1300: D (0.6931226253509521 real_err, 0.6932374238967896 fake_err) G (0.6930371522903442 err); Real Dist ([3.0017813444137573, 1.1533314994521284]),  Fake Dist ([1.3266445994377136, 1.7869840386833384]) \n",
      "Epoch 1400: D (0.6931366920471191 real_err, 0.6931740045547485 fake_err) G (0.6931029558181763 err); Real Dist ([3.0040394067764282, 1.150951856278382]),  Fake Dist ([1.1311806440353394, 1.9388417035823056]) \n",
      "Epoch 1500: D (0.6933085918426514 real_err, 0.6928954124450684 fake_err) G (0.6932265758514404 err); Real Dist ([3.004382610321045, 1.1518802708896698]),  Fake Dist ([1.563184142112732, 1.7031316256137699]) \n",
      "Epoch 1600: D (0.6928570866584778 real_err, 0.6934691071510315 fake_err) G (0.6930505037307739 err); Real Dist ([3.0022048950195312, 1.1516591968492327]),  Fake Dist ([1.3059788346290588, 1.8517725668658285]) \n",
      "Epoch 1700: D (0.6937299370765686 real_err, 0.6927904486656189 fake_err) G (0.6936420202255249 err); Real Dist ([2.9951688051223755, 1.1493754304308814]),  Fake Dist ([1.6605596542358398, 1.6406851607712531]) \n",
      "Epoch 1800: D (0.6930892467498779 real_err, 0.693183183670044 fake_err) G (0.6930484771728516 err); Real Dist ([3.007545590400696, 1.1489087797477668]),  Fake Dist ([1.1765520572662354, 1.9435966537951321]) \n",
      "Epoch 1900: D (0.6930376291275024 real_err, 0.6933064460754395 fake_err) G (0.6930619478225708 err); Real Dist ([2.9928441047668457, 1.1472457000344785]),  Fake Dist ([1.642171025276184, 1.687251048605657]) \n",
      "Epoch 2000: D (0.6931725740432739 real_err, 0.6931324005126953 fake_err) G (0.6931318044662476 err); Real Dist ([2.9996626377105713, 1.1525995186239688]),  Fake Dist ([1.4732986688613892, 1.7633274989095076]) \n",
      "Epoch 2100: D (0.693248987197876 real_err, 0.6931641101837158 fake_err) G (0.6933695673942566 err); Real Dist ([3.009652853012085, 1.1478914399620568]),  Fake Dist ([1.4134700298309326, 1.783477379047843]) \n",
      "Epoch 2200: D (0.6933707594871521 real_err, 0.692783772945404 fake_err) G (0.6934782862663269 err); Real Dist ([3.001794457435608, 1.1528864606148101]),  Fake Dist ([1.098657488822937, 1.9553699476889594]) \n",
      "Epoch 2300: D (0.6931219100952148 real_err, 0.6932997703552246 fake_err) G (0.6929442882537842 err); Real Dist ([2.9968217611312866, 1.1527525222329014]),  Fake Dist ([1.0781612396240234, 1.9920976277587046]) \n",
      "Epoch 2400: D (0.6931099891662598 real_err, 0.6931573152542114 fake_err) G (0.6930538415908813 err); Real Dist ([2.997810959815979, 1.152382643063129]),  Fake Dist ([1.5242626667022705, 1.7366713519459784]) \n",
      "Epoch 2500: D (0.6928249001502991 real_err, 0.693485677242279 fake_err) G (0.6930407285690308 err); Real Dist ([3.0014119148254395, 1.1490093367755]),  Fake Dist ([1.8126072585582733, 1.573579708505723]) \n",
      "Epoch 2600: D (0.693213939666748 real_err, 0.6928462386131287 fake_err) G (0.6932480335235596 err); Real Dist ([2.999966859817505, 1.1535653065864264]),  Fake Dist ([0.972184419631958, 2.0694601893700297]) \n",
      "Epoch 2700: D (0.6932933330535889 real_err, 0.6930441856384277 fake_err) G (0.6934151649475098 err); Real Dist ([3.001962423324585, 1.1526344830114352]),  Fake Dist ([1.6368985772132874, 1.665148909868324]) \n",
      "Epoch 2800: D (0.6931612491607666 real_err, 0.6931519508361816 fake_err) G (0.6934244632720947 err); Real Dist ([2.994645833969116, 1.1478325235926252]),  Fake Dist ([1.634901762008667, 1.6624708649192617]) \n",
      "Epoch 2900: D (0.6931798458099365 real_err, 0.6932239532470703 fake_err) G (0.6930534839630127 err); Real Dist ([2.996331572532654, 1.1510582636465376]),  Fake Dist ([1.5479655265808105, 1.7241101892660726]) \n",
      "Epoch 3000: D (0.6932215690612793 real_err, 0.6930670738220215 fake_err) G (0.6932291984558105 err); Real Dist ([3.0071945190429688, 1.1466620425429135]),  Fake Dist ([1.173880696296692, 1.959721637377838]) \n",
      "Epoch 3100: D (0.6927699446678162 real_err, 0.6935102343559265 fake_err) G (0.6928237080574036 err); Real Dist ([2.992173671722412, 1.149969067914932]),  Fake Dist ([1.1933510303497314, 1.9193740419647711]) \n",
      "Epoch 3200: D (0.6932189464569092 real_err, 0.6931220293045044 fake_err) G (0.6933664679527283 err); Real Dist ([3.002777934074402, 1.1460567043780179]),  Fake Dist ([1.3387606739997864, 1.8380094001254639]) \n",
      "Epoch 3300: D (0.6929796934127808 real_err, 0.6931824684143066 fake_err) G (0.692956805229187 err); Real Dist ([3.0049930810928345, 1.1508833040541369]),  Fake Dist ([1.1846461296081543, 1.9203961308503537]) \n",
      "Epoch 3400: D (0.6930621862411499 real_err, 0.6932613849639893 fake_err) G (0.6931248903274536 err); Real Dist ([3.002190589904785, 1.1518337434764272]),  Fake Dist ([1.4216908812522888, 1.7847236047991428]) \n",
      "Epoch 3500: D (0.6929036378860474 real_err, 0.69333815574646 fake_err) G (0.6928538680076599 err); Real Dist ([2.9977515935897827, 1.1529171576951447]),  Fake Dist ([1.414415419101715, 1.8125741847943488]) \n",
      "Epoch 3600: D (0.6933010816574097 real_err, 0.6929795742034912 fake_err) G (0.6934177875518799 err); Real Dist ([2.9841651916503906, 1.1452780584815467]),  Fake Dist ([1.6930020451545715, 1.628596946493858]) \n",
      "Epoch 3700: D (0.6930557489395142 real_err, 0.6932531595230103 fake_err) G (0.6930217742919922 err); Real Dist ([3.018643617630005, 1.1422115165146614]),  Fake Dist ([1.585238754749298, 1.7171397151352352]) \n",
      "Epoch 3800: D (0.6932816505432129 real_err, 0.6929813623428345 fake_err) G (0.693221926689148 err); Real Dist ([2.9975006580352783, 1.1514556050025289]),  Fake Dist ([1.2899922132492065, 1.878249246033455]) \n",
      "Epoch 3900: D (0.6931676864624023 real_err, 0.6931928396224976 fake_err) G (0.6931285858154297 err); Real Dist ([3.002394676208496, 1.1497088998349654]),  Fake Dist ([1.5478770732879639, 1.752988708487284]) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4000: D (0.693008542060852 real_err, 0.6933802366256714 fake_err) G (0.6929229497909546 err); Real Dist ([3.002164125442505, 1.1493723331918342]),  Fake Dist ([1.2384406328201294, 1.91048434645144]) \n",
      "Epoch 4100: D (0.6935232281684875 real_err, 0.6929752826690674 fake_err) G (0.6935425996780396 err); Real Dist ([3.0089781284332275, 1.1493054328284142]),  Fake Dist ([1.4834959506988525, 1.7436713875028333]) \n",
      "Epoch 4200: D (0.6929671764373779 real_err, 0.693234920501709 fake_err) G (0.6930090188980103 err); Real Dist ([2.9970507621765137, 1.1528917603349575]),  Fake Dist ([1.5200074911117554, 1.7292059734291623]) \n",
      "Epoch 4300: D (0.6933943629264832 real_err, 0.6929514408111572 fake_err) G (0.693332850933075 err); Real Dist ([2.9966161251068115, 1.1517132952912574]),  Fake Dist ([1.7154915928840637, 1.6422024981804864]) \n",
      "Epoch 4400: D (0.6930056810379028 real_err, 0.693150520324707 fake_err) G (0.6929960250854492 err); Real Dist ([2.996348738670349, 1.1506876962014214]),  Fake Dist ([1.6250126957893372, 1.6838924369966186]) \n",
      "Epoch 4500: D (0.6934304237365723 real_err, 0.6930413246154785 fake_err) G (0.6933419108390808 err); Real Dist ([2.995816707611084, 1.1495720706966128]),  Fake Dist ([1.399263083934784, 1.8175332774741546]) \n",
      "Epoch 4600: D (0.6932618618011475 real_err, 0.6933386325836182 fake_err) G (0.692876398563385 err); Real Dist ([2.9983832836151123, 1.1533574474325907]),  Fake Dist ([1.8854852318763733, 1.5322732250905202]) \n",
      "Epoch 4700: D (0.6931545734405518 real_err, 0.6931033134460449 fake_err) G (0.6931145191192627 err); Real Dist ([2.993589401245117, 1.146821997732819]),  Fake Dist ([1.8208398222923279, 1.5955808600432329]) \n",
      "Epoch 4800: D (0.6932382583618164 real_err, 0.6931775808334351 fake_err) G (0.6931524276733398 err); Real Dist ([3.0004160404205322, 1.1537054394464294]),  Fake Dist ([1.2053501605987549, 1.9604544441364105]) \n",
      "Epoch 4900: D (0.6933023929595947 real_err, 0.6930892467498779 fake_err) G (0.6932671070098877 err); Real Dist ([2.99802029132843, 1.151709785087004]),  Fake Dist ([1.3896934986114502, 1.8454287674355452]) \n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "        for d_index in range(d_steps):\n",
    "            # 1. Train D on real+fake\n",
    "            D.zero_grad()\n",
    "\n",
    "            #  1A: Train D on real\n",
    "            d_real_data = Variable(d_sampler(d_input_size, 1))\n",
    "            d_real_decision = D(preprocess(d_real_data))\n",
    "            d_real_error = criterion(d_real_decision, Variable(torch.ones([1,1])))  # ones = true\n",
    "            d_real_error.backward() # compute/store gradients, but don't change params\n",
    "\n",
    "            #  1B: Train D on fake\n",
    "            d_gen_input = Variable(gi_sampler(minibatch_size))\n",
    "            d_fake_data = G(d_gen_input).detach()  # detach to avoid training G on these labels\n",
    "            d_fake_decision = D(preprocess(d_fake_data.t()))\n",
    "            d_fake_error = criterion(d_fake_decision, Variable(torch.zeros([1,1])))  # zeros = fake\n",
    "            d_fake_error.backward()\n",
    "            d_optimizer.step()     # Only optimizes D's parameters; changes based on stored gradients from backward()\n",
    "\n",
    "            dre, dfe = extract(d_real_error)[0], extract(d_fake_error)[0]\n",
    "\n",
    "        for g_index in range(g_steps):\n",
    "            # 2. Train G on D's response (but DO NOT train D on these labels)\n",
    "            G.zero_grad()\n",
    "\n",
    "            gen_input = Variable(gi_sampler(minibatch_size))\n",
    "            g_fake_data = G(gen_input)\n",
    "            dg_fake_decision = D(preprocess(g_fake_data.t()))\n",
    "            g_error = criterion(dg_fake_decision, Variable(torch.ones([1,1])))  # Train G to pretend it's genuine\n",
    "\n",
    "            g_error.backward()\n",
    "            g_optimizer.step()  # Only optimizes G's parameters\n",
    "            ge = extract(g_error)[0]\n",
    "        \n",
    "        \n",
    "        \n",
    "        if epoch % print_interval == 0:\n",
    "            print(\"Epoch %s: D (%s real_err, %s fake_err) G (%s err); Real Dist (%s),  Fake Dist (%s) \" %\n",
    "                  (epoch, dre, dfe, ge, stats(extract(d_real_data)), stats(extract(d_fake_data))))\n",
    "   \n",
    "            \n",
    "\n",
    "torch.save(G.state_dict(),'Generator_Model.pth')\n",
    "torch.save(D.state_dict(),'Discriminator_Model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the trained G and D Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = Generator(input_size=g_input_size,\n",
    "                  hidden_size=g_hidden_size,\n",
    "                  output_size=g_output_size,\n",
    "                  f=generator_activation_function)\n",
    "D = Discriminator(input_size=d_input_func(d_input_size),\n",
    "                  hidden_size=d_hidden_size,\n",
    "                  output_size=d_output_size,\n",
    "                  f=discriminator_activation_function)\n",
    "\n",
    "G.load_state_dict(torch.load('Generator_Model.pth'))\n",
    "D.load_state_dict(torch.load('Discriminator_Model.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Fake Data using G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_input = Variable(gi_sampler(minibatch_size))\n",
    "generated_data = extract(G(noise_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample from Real Data (R) Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data = extract(Variable(d_sampler(d_input_size, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stats Comparison between Fake and Real Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = {}\n",
    "stats['Generated'] = [round(np.mean(generated_data),2),round(np.std(generated_data),2)]\n",
    "stats['Real'] = [round(np.mean(real_data),2),round(np.std(real_data),2)]\n",
    "stats['Expected'] = [round((data_upper+data_lower)/2,2),round((data_upper-data_lower)/3.464,2)]\n",
    "stats_df = pd.DataFrame(stats)\n",
    "stats_df.index = ['Mean','Std Dev']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Generated</th>\n",
       "      <th>Real</th>\n",
       "      <th>Expected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Mean</td>\n",
       "      <td>3.03</td>\n",
       "      <td>2.97</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Std Dev</td>\n",
       "      <td>1.18</td>\n",
       "      <td>1.15</td>\n",
       "      <td>1.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Generated  Real  Expected\n",
       "Mean          3.03  2.97      3.00\n",
       "Std Dev       1.18  1.15      1.15"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
